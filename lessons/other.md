## Движки семейства *Log

### TinyLog
- Самый простой движок.
- Каждый столбец хранится в отдельном файле (как и в Log).
- Не поддерживает многопоточного чтения (в отличие от Log и StripeLog).
- Записи при чтении отсортированы в порядке вставки.

### Log
- Расширяет возможности TinyLog многопоточным чтением.
- Реализуется с помощью файла засечек (index.mrk).
- Засечки пишутся на каждый блок данных и содержат смещение (с какого места читать файл, чтобы пропустить заданное количество строк).

### StripeLog
- Хранит все столбцы в одном файле:
  - `data.bin` – файл с данными.
  - `index.mrk` – файл с метками (смещения для каждого столбца каждого вставленного блока данных).
- При INSERT добавляет блок данных в конец файла таблицы, записывая столбцы один за другим.

### Синтаксис CREATE TABLE
```sql
CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster] (
    column1_name [type1] [DEFAULT|MATERIALIZED|ALIAS expr1],
    ...
) ENGINE = [StripeLog | Log | TinyLog];
```

---

## Движок Buffer
- Предназначен для буферизации данных в памяти для ускорения вставки в другую таблицу.
- Рекомендуется вставлять блоками (хотя бы по 10 записей).
- При чтении из буферной таблицы чтение происходит также и из целевой таблицы.
- При разнице структур столбцов в целевой и буферной таблице вставляются данные совпадающих столбцов (типы данных должны совпадать, иначе INSERT завершится ошибкой).
- Можно указать пустые кавычки вместо целевой таблицы — будет просто буфер с периодической очисткой.

### Синтаксис CREATE TABLE
```sql
CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster] (
    column1_name [type1] [DEFAULT|ALIAS expr1],
    ...
) ENGINE = Buffer(
    database, target_table,
    num_layers,
    min_time, max_time,
    min_rows, max_rows,
    min_bytes, max_bytes
    [, flush_time [, flush_rows [, flush_bytes]]]
);
```
- `num_layers` — уровень параллелизма (количество независимых буферов, рекомендуется 16).
- Данные сбрасываются из буфера в таблицу назначения, если выполнены все min-условия или хотя бы одно max-условие.
- Условия учитываются отдельно для каждого буфера.

### Недостатки Buffer
- `FINAL` и `SAMPLE` не учитывают данные в буфере.
- Блокировка одного из буферов при вставке может влиять на скорость чтения.
- Сброс данных в порядке, отличном от вставки, негативно влияет на CollapsingMergeTree (нерегулируемый порядок вставки) и реплицируемые таблицы.

### Альтернатива: async_insert
- `async_insert = 1` – включить асинхронные вставки.
- `async_insert_threads` – число потоков для фоновой обработки и вставки данных (по умолчанию 16).
- `wait_for_async_insert` – ожидать или нет записи данных в таблицу.
- `wait_for_async_insert_timeout` – время ожидания в секундах (0 – ожидание отключено).

---

## Движок Join
- Предназначен для предварительной подготовки данных для использования в операциях JOIN.
- Таблица используется в правой части секции JOIN или в функции `joinGet`.
- Данные всегда в ОЗУ, но могут храниться на диске (опция `persistent`), однако при аварийной остановке данные могут быть повреждены.
- Поддерживаются DELETE мутации.
- Нельзя использовать в GLOBAL JOIN.
- Не поддерживается сэмплирование, индексы и репликация.

### Синтаксис
```sql
CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster] (
    fld [type1] [DEFAULT|MATERIALIZED|ALIAS expr1] [TTL expr1],
    ...
) ENGINE = Join(
    [ANY | ALL],        -- строгость соединения
    [INNER | LEFT | ...], -- тип соединения
    fld[, fld2, ...]    -- ключевые столбцы секции USING
)
SETTINGS
    persistent = [1 | 0],
    join_use_nulls = [1 | 0],
    max_rows_in_join = 0,
    max_bytes_in_join = 0,
    join_overflow_mode = [THROW | BREAK],
    join_any_take_last_row = [1 | 0];
```

### Параметры движка
- `join_strictness` – строгость JOIN (ANY, ALL).
- `join_type` – тип JOIN (INNER, LEFT, RIGHT, FULL, CROSS).
- `k1[, k2, ...]` – ключевые столбцы секции USING.
- Параметры `join_strictness` и `join_type` должны совпадать с операцией JOIN, иначе возможны неверные данные.

### Дополнительные настройки
- `persistent` – хранить ли данные на диске.
- `join_use_nulls` – чем заполнять пустые ячейки (0 – значения по умолчанию, 1 – NULL).
- `max_rows_in_join`, `max_bytes_in_join` – ограничения на размер хэш-таблицы (по умолчанию 0).
- `join_overflow_mode` – действие при переполнении (THROW – остановить запрос, BREAK – прервать без исключения).
- `join_any_take_last_row` – какие строки присоединять при совпадении (0 – первая, 1 – последняя).

---

## Движки URL и File

### Движок URL
- Для работы с данными на удаленном сервере.
- Запросы INSERT и SELECT транслируются в POST и GET запросы.
- Можно обращаться к таблице в другом ClickHouse через HTTP.
- Поддерживается многопоточная запись и чтение.
- Не хранит данные локально.
- Не поддерживаются ALTER, сэмплирование, индексы, репликация.

#### Пример
```sql
CREATE TABLE url_engine_table (
    `SIC Code` Nullable(Int64),
    `Description` Nullable(String)
) ENGINE = URL('https://cdn.wsform.com/wp-content/uploads/2020/06/industry_site.csv', CSV);
```

### Движок File
- Управляет данными в одном файле на диске в указанном формате.
- Применение: выгрузка данных из ClickHouse в файл, преобразование форматов, обновление данных редактированием файла.
- Поддерживается множественное выполнение SELECT, INSERT сериализуются.
- При CREATE создается директория (можно поместить файл и прикрепить через ATTACH).
- Для существующих файлов INSERT записывает в конец.
- Не поддерживаются: ALTER, SELECT...SAMPLE, индексы, репликация.

---

## Движки Set и Memory

### Движок Set
- Множество в оперативной памяти на основе хэш-таблицы.
- Используется в операторе IN (нельзя сделать SELECT из таблицы).
- Можно вставлять данные через INSERT (возможны дубликаты).
- Данные могут храниться на диске (опция `persistent`).

### Движок Memory
- Данные хранятся только в оперативной памяти в несжатом виде.
- Уместно использовать на датасетах до 10М строк для достижения высокой скорости.
- Чтение распараллеливается, чтение и запись не блокируют друг друга.
- Индексы не поддерживаются.
- Подходит для GLOBAL IN.

---

## Движок Merge
- Не относится к семейству MergeTree.
- Позволяет делать запрос к нескольким таблицам одновременно (вариант UNION).
- Имена таблиц можно задать через RegExp.
- INSERT не поддерживается.
- При выборке имеет виртуальный столбец `table`.
- Столбцы в таблице должны существовать в таблицах источника.

#### Синтаксис
```sql
CREATE TABLE ... ENGINE = Merge(db_name, table_regexp);
```

#### Применение
- Работа с большим набором таблиц как с одной (например, с *Log).
- Партиционирование существующей таблицы:
  1. Создать новую таблицу с партициями.
  2. Создать Merge таблицу для чтения из старой и новой.
  3. Запись происходит только в новую.

---

## Специализированные движки для интеграций
ClickHouse интегрируется с другими системами через движки:
- MySQL и MaterializedMySQL
- PostgreSQL и MaterializedPostgreSQL
- Hive
- MongoDB
- HDFS
- Kafka
- SQLite
- ODBC и JDBC

---

## Materialized View (MV)
- Хранят данные, выбранные запросом SELECT, указанным при создании.
- Содержимое может быть реплицировано.
- SELECT можно делать как из MV, так и из целевой таблицы.
- Принцип работы отличается от других СУБД (похоже на триггер AFTER INSERT).
- Если в запросе есть агрегирование, оно применяется только к вставляемому блоку записей.
- Обновления в исходной таблице не влияют на данные в MV, только вставки.

### Синтаксис
```sql
CREATE MATERIALIZED VIEW [IF NOT EXISTS] [db.]mv_name [ON CLUSTER]
[TO [db.]table]                     -- явно указать таблицу для хранения данных
[                                   -- имена полей и типы
    (fld_1 Type_1, fld_2 Type_2, ...)
]
[ENGINE = engine]                   -- указать движок, если не указана таблица в "TO"
[POPULATE]                          -- сразу загрузить данные из источника
AS
SELECT                               -- SELECT преобразование
    expr(f1) as fld_1,
    expr(f2) as fld_2, ...
FROM source_tbl                     -- выборка из таблицы-источника
[GROUP BY] [ORDER BY];
```

### Сценарии использования MV
- Агрегация данных.
- Обработка потоков данных из внешних источников.
- Маршрутизация и преобразование данных (несколько MV для одного источника).
- Дублирование данных для изменения ключа сортировки.

---

## Проекции
- Данные проекций всегда согласованы с таблицей.
- Обновляются атомарно вместе с таблицей.
- Содержимое реплицируется вместе с таблицей.
- Проекция может быть автоматически использована для запроса SELECT.

### Условия использования проекции
1. Выборка соответствует запросу проекции.
2. 50% выбранных кусков содержат материализованные проекции.
3. Количество выбранных строк меньше общего количества строк таблицы.

#### Пример
```sql
CREATE TABLE visits (
    user_id UInt64,
    user_name String,
    pages_visited Nullable(Float64),
    user_agent String,
    PROJECTION projection_visits_by_user (
        SELECT user_agent, sum(pages_visited)
        GROUP BY user_id, user_agent
    )
) ENGINE = MergeTree()
ORDER BY user_agent;
```

---

## Движок Kafka
### Основные понятия Kafka
- Record – запись (ключ и значение).
- Topic – категория или имя потока.
- Producer – процесс, публикующий данные в топик.
- Consumer – процесс, читающий данные из топика.
- Consumer group – группа читателей для балансировки нагрузки.
- Offset – позиция записи.
- Partition – шард топика.

### Особенности движка Kafka в ClickHouse
- Одна из самых частых интеграций.
- Не хранит данные самостоятельно, предназначен для подписки на потоки (consumer) и публикации данных (producer).
- SELECT может прочесть запись только один раз.
- Имеет смысл использовать с Materialized View.

### Обязательные настройки
- `kafka_broker_list` – перечень брокеров.
- `kafka_topic_list` – перечень топиков.
- `kafka_group_name` – группа потребителя (для избежания повторений на кластере использовать одно имя).
- `kafka_format` – формат сообщений (например, JSONEachRow).

### Пример организации пайплайна
```sql
CREATE TABLE kafka_tbl (
    Message String,
    Priority String
) ENGINE = Kafka
SETTINGS
    kafka_broker_list = '127.0.0.1:29092',
    kafka_topic_list = 'MyOtusTopic',
    kafka_group_name = 'test-consumer-group',
    kafka_format = 'JSONEachRow';
```
