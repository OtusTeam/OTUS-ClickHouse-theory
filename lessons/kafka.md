## 1. Основные понятия Apache Kafka

### 1.1. Потоковая обработка данных
- **Поток данных (stream)** — это именованный неограниченный набор записей (сообщений).
- **Пакет (batch)** — это конечный набор записей.
- **Потребность в потоковой обработке:** необходимость получать результат практически в режиме реального времени (финансовые транзакции, действия в онлайн-магазинах, данные с датчиков и т.д.).

### 1.2. Что такое Kafka?
Kafka — это **распределенная потоковая платформа**, которая умеет:
- Публиковать записи и подписываться на очереди сообщений (Publish/Subscribe).
- Хранить записи с отказоустойчивостью.
- Обрабатывать потоки по мере их возникновения.

**Платформа включает:**
- **API:** Producer, Consumer, Admin.
- Kafka Streams
- Kafka Connect
- ksqlDB

Kafka — это масштабируемая шина сообщений, используемая для построения Data Pipelines и ETL процессов.

### 1.3. Основные концепции и архитектура
- **Record (Запись):** Элемент данных типа «ключ-значение».
- **Topic (Тема):** Имя потока с данными (категория), куда публикуются записи.
- **Partition (Раздел/Секция):** Шард (сегмент) топика для параллелизма.
- **Offset (Смещение):** Уникальная позиция записи внутри раздела.
- **Producer:** Процесс, публикующий записи в топик.
- **Consumer:** Процесс, читающий записи из топика.
- **Consumer Group:** Группа читателей из одного топика для балансировки нагрузки по чтению. Разные consumer groups читают независимо друг от друга.
- **Broker:** Сервер Kafka, управляющий данными и взаимодействующий с клиентами.
- **ZooKeeper / KRaft:**
    - **ZooKeeper (традиционно):** Отвечает за членство брокеров в кластере и выборы контроллера.
    - **Контроллер:** Брокер, отвечающий за выбор ведущих реплик для разделов.
    - **KRaft (новый режим):** Узлы могут быть брокерами или контроллерами (3 или 5). Активный контроллер является лидером Raft, а журнал метаданных хранит информацию об изменениях в кластере.

### 1.4. Чтение и фиксация смещений (Offset Commit)
- Брокер Kafka **не отслеживает** чтение потребителями.
- Потребители сами сохраняют свою позицию (смещение) в Kafka, отправляя сообщения в специальную тему **`__consumer_offsets`**.
- Действие по обновлению позиции называется **фиксацией (commit)**.
- Сбой потребителя или присоединение нового вызывает **перебалансировку**.

## 2. Варианты применения Kafka
- Агрегация и доставка журналов (log shipping).
- Сложная обработка событий (Complex Event Processing).
- Паттерн CQRS (Command-Query Responsibility Segregation).
- Model-on-Demand.

## 3. Запуск и установка Kafka

### 3.1. Ручной запуск (на примере версии 2.13-3.6.1)
1.  Распаковать архив: `tar -zxvf kafka_2.13-3.6.1.tgz`
2.  Запустить ZooKeeper: `bin/zookeeper-server-start.sh -daemon config/zookeeper.properties`
3.  Запустить Kafka Broker: `bin/kafka-server-start.sh -daemon config/server.properties`
4.  Создать тему: `bin/kafka-topics.sh --create --topic quickstart --bootstrap-server localhost:9092`
5.  Записать сообщения (продюсер): `bin/kafka-console-producer.sh --topic quickstart --bootstrap-server localhost:9092`
6.  Прочитать сообщения (консюмер): `bin/kafka-console-consumer.sh --topic quickstart --from-beginning --bootstrap-server localhost:9092`

### 3.2. Kafka в Docker (docker-compose.yml)
Используются образы `confluentinc/cp-zookeeper:latest` и `confluentinc/cp-kafka:latest` с настройками портов и переменных окружения.

### 3.3. Основные скрипты для операций
- `zookeeper-server-start.sh` / `zookeeper-server-stop.sh`
- `kafka-server-start.sh` / `kafka-server-stop.sh`
- `kafka-console-producer.sh`
- `kafka-console-consumer.sh`
- `kafka-topics.sh`

## 4. Варианты интеграции с ClickHouse

### 4.1. Self-managed Kafka Connectivity
1.  **Kafka Connect:** Бесплатный компонент Apache Kafka, работающий как централизованный дата-хаб для интеграции данных.
2.  **Vector:** Конвейер данных, не зависящий от источника (может читать из Kafka и отправлять в ClickHouse).
3.  **JDBC Connect Sink:** Позволяет экспортировать данные из топиков Kafka в любую БД с JDBC-драйвером.
4.  **Custom code:** Пользовательский код с клиентскими библиотеками для Kafka и ClickHouse.
5.  **Kafka table engine (нативный движок ClickHouse):** Обеспечивает нативную интеграцию (недоступна в ClickHouse Cloud).

## 5. Движок Kafka (Kafka Engine)

### 5.1. Особенности
- Одна из самых частых интеграций.
- **Не хранит данные самостоятельно.** Предназначен для подписки на потоки (consumer) и публикации данных (producer).
- При выполнении `SELECT` запись можно прочесть только один раз.
- Поэтому имеет смысл использовать в связке с **Materialized View (MV)**.

### 5.2. Обязательные настройки движка
- `kafka_broker_list` — список брокеров через запятую.
- `kafka_topic_list` — список необходимых топиков Kafka через запятую.
- `kafka_group_name` — группа потребителя. Чтобы сообщения не дублировались на кластере, нужно использовать везде одно имя группы.
- `kafka_format` — формат сообщений (например, `JSONEachRow`).
- Существуют также опциональные параметры (размер блока, количество потребителей и т.д.).

### 5.3. Пример организации пайплайна (INSERT -> Kafka -> MV -> Target)
```sql
-- Целевая таблица для хранения данных
CREATE TABLE log_target (id UInt64, msg String) ENGINE = TinyLog ORDER BY (id);

-- Таблица с движком Kafka (приемник данных из Kafka)
-- Предполагается, что она уже создана как kafka_tbl

-- Материализованное представление, которое читает из kafka_tbl и пишет в log_target
CREATE MATERIALIZED VIEW kafka_mv TO log_target AS SELECT id, msg FROM kafka_tbl;

-- Отправка данных в Kafka через движок (INSERT в kafka_tbl)
INSERT INTO kafka_tbl SELECT number as id, concat('test',number) as msg FROM numbers(10) FORMAT JSONEachRow;

-- Проверка данных в целевой таблице
SELECT * FROM log_target;
```

## 6. Kafka Connect

### 6.1. Что это?
Kafka Connect — это часть Kafka, обеспечивающая масштабируемый и гибкий способ копирования данных между Kafka и другими системами. Это среда выполнения для плагинов-коннекторов с общим фреймворком.

### 6.2. Возможности Kafka Connect
- Управление настройками и хранение смещений.
- Распараллеливание (масштабируемость) и автоматическое восстановление.
- Обработка ошибок.
- Поддержка различных типов данных.
- REST API.

### 6.3. Основные параметры коннекторов
- `name` — уникальное имя коннектора.
- `connector.class` — Java класс коннектора.
- `tasks.max` — максимальное количество задач.
- `key.converter` / `value.converter` — преобразователи ключей/значений.
- **Для коннекторов-приемников (Sink):** `topics` (список тем) или `topics.regex`.

### 6.4. Преобразователи (Converters и SMT)
- **Конвертеры (Converters):** Нужны для обеспечения одинакового формата данных при записи в Kafka и чтении из нее (преобразование байтов во внутренний формат Connect и обратно).
- **Single Message Transforms (SMT):** Преобразования одиночных сообщений. Примеры применения:
    - Удаление, переименование, добавление полей.
    - Изменение типов данных (`Cast`).
    - Маскировка полей (`MaskField`).
    - Фильтрация сообщений (`Filter`).
    - Изменение топика назначения на основе времени (`TimestampRouter`) или регулярного выражения (`RegexRouter`).

## 7. Подводные камни

### 7.1. Аутентификация и безопасность (Kerberos)
- Ошибки коннекта из-за несовместимости версий Kerberos.
- Проблемы с протуханием кеша и некорректной работой процессов его обновления.
- Необходимость хранить keytab-файл на сервере.

### 7.2. Потеря данных и гарантии доставки
- Иногда интеграция работает не с гарантией **exactly-once**, а чаще с **at most once** (некоторые сообщения могут быть потеряны).
- Существуют обсуждения и материалы по настройке exactly-once (ссылки в документе).

### 7.3. Производительность
- Высокая нагрузка на сервер и слабая скорость при использовании **Kafka Engine** (есть ссылки на обсуждения и замеры латентности).

### 7.4. Сложности разработки и эксплуатации
- Написание собственных consumer-сервисов может вызывать проблемы при разработке и отладке.
- **Проблемные версии** ПО (есть ссылка на issue в GitHub).
- **Кривая обработка ошибок:**
    - Неверный формат данных может привести к появлению пустых строк без явных ошибок.
    - Не стоит полагаться на логи — они могут быть бесполезны в таких ситуациях.
- Разные результаты при выполнении `SELECT` из таблицы с Kafka Engine и целевой `MergeTree` (из-за особенностей чтения).
